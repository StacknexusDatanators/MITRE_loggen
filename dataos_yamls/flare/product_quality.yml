---
version: v1beta1
name: productquality-data-01
type: workflow
tags:
  - Metrics
  - Checks
description: The job performs metrics calculations and checks on product quality data
#owner: itspiyush
workflow:
  title: Metrics and checks
  dag:
    - name: productquality-productdata-01
      title: Metrics and checks
      description: The job performs metrics calculations and checks on product quality data
      spec:
        stack: flare:1.0
        envs:
          SKIP_TOPOLOGY_REGISTRATION: "true"
        tags:
          - Metrics
        title: Metrics and checks
        description: The job performs metrics calculations and checks on product quality data
        flare:
          driver:
            coreLimit: 4000m
            cores: 2
            memory: 6144m
          executor:
            coreLimit: 6000m
            cores: 2
            instances: 3
            memory: 10000m
          job:
            explain: true
            logLevel: INFO
            #validate single input
            inputs:
              - name: input_df
                dataset: dataos://icebase:merchandise_retail/retail_product
                format: iceberg
            #override outputs, steps with specific template
            assertions:
              - column: product_price
                tests:
                  - min > 0
              - column: product_stock
                tests:
                  - min > 0
                  - avg > 10000
              - sql: |
                  SELECT
                    AVG(CAST(productrevenue as INT)) as avg_revenue,
                    AVG(product_price) as avg_price
                  FROM input_df
                tests:
                  - avg_revenue > avg_price
          sparkConf:
            - spark.serializer: org.apache.spark.serializer.KryoSerializer
            - spark.sql.shuffle.partitions: "10"
            - spark.memory.storageFraction: "0.1"
            - spark.memory.fraction: "0.1"
            - spark.shuffle.memoryFraction: "0.2"