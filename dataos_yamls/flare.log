NODE NAME                    |     CONTAINER NAME      | ERROR
-------------------------------------------------|-------------------------|--------
retaildb-write-postgres-9611-0713115359-driver | spark-kubernetes-driver |

-------------------LOGS-------------------
++ id -u
+ myuid=0
++ id -g
+ mygid=0
+ set +e
++ getent passwd 0
+ uidentry=root:x:0:0:root:/root:/bin/bash
+ set -e
+ '[' -z root:x:0:0:root:/root:/bin/bash ']'
+ SPARK_CLASSPATH=':/opt/spark/jars/*'
+ env
+ grep SPARK_JAVA_OPT_
+ sort -t_ -k4 -n
+ sed 's/[^=]*=\(.*\)/\1/g'
+ readarray -t SPARK_EXECUTOR_JAVA_OPTS
+ '[' -n '' ']'
+ '[' -z ']'
+ '[' -z ']'
+ '[' -n '' ']'
+ '[' -z ']'
+ '[' -z x ']'
+ SPARK_CLASSPATH='/opt/spark/conf::/opt/spark/jars/*'
+ case "$1" in
+ shift 1
+ CMD=("$SPARK_HOME/bin/spark-submit" --conf "spark.driver.bindAddress=$SPARK_DRIVER_BIND_ADDRESS" --deploy-mode client "$@")
+ exec /usr/bin/tini -s -- /opt/spark/bin/spark-submit --conf spark.driver.bindAddress=10.212.3.248 --deploy-mode client --properties-file /opt/spark/conf/spark.properties --class io.dataos.flare.Flare local:///opt/spark/jars/flare.jar -c /etc/dataos/config/jobconfig.yaml
2022-07-13 11:54:29,770 WARN  [main] o.a.h.u.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
build version: 5.7.12; workspace name: public; workflow name: retail-postgres-write; workflow run id: c9e73a1f-e0c8-4f27-9b26-fb82d12def08; run as user: rakeshvishvakarma; job name: retaildb-write-postgres; job run id: 23ac3e82-a24b-484b-a275-b47b5167e331;
found configuration: Map(explain -> true, appName -> retaildb-write-postgres, outputs -> List(Map(depot -> dataos://retailsdbsdatabase:public?acl=rw, driver -> org.postgresql.Driver, name -> customer)), inputs -> List(Map(dataset -> dataos://icebase:merchandise_retail/retail_customer, format -> iceberg, name -> input)), steps -> List(/etc/dataos/config/step-0.yaml), logLevel -> INFO)
22/07/13 11:54:33 INFO Flare$: context is io.dataos.flare.contexts.ProcessingContext@4779aae6
2022-07-13 11:54:34,255 INFO  [main] o.a.h.hive.conf.HiveConf: Found configuration file null
2022-07-13 11:54:34,633 INFO  [main] o.a.spark.SparkContext: Running Spark version 3.2.1
2022-07-13 11:54:34,662 INFO  [main] o.a.s.r.ResourceUtils: ==============================================================
2022-07-13 11:54:34,662 INFO  [main] o.a.s.r.ResourceUtils: No custom resources configured for spark.driver.
2022-07-13 11:54:34,663 INFO  [main] o.a.s.r.ResourceUtils: ==============================================================
2022-07-13 11:54:34,664 INFO  [main] o.a.spark.SparkContext: Submitted application: retaildb-write-postgres
2022-07-13 11:54:34,725 INFO  [main] o.a.s.r.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-07-13 11:54:34,745 INFO  [main] o.a.s.r.ResourceProfile: Limiting resource is cpus at 1 tasks per executor
2022-07-13 11:54:34,748 INFO  [main] o.a.s.r.ResourceProfileManager: Added ResourceProfile id: 0
2022-07-13 11:54:34,927 INFO  [main] o.a.spark.SecurityManager: Changing view acls to: root
2022-07-13 11:54:34,928 INFO  [main] o.a.spark.SecurityManager: Changing modify acls to: root
2022-07-13 11:54:34,929 INFO  [main] o.a.spark.SecurityManager: Changing view acls groups to:
2022-07-13 11:54:34,930 INFO  [main] o.a.spark.SecurityManager: Changing modify acls groups to:
2022-07-13 11:54:34,930 INFO  [main] o.a.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2022-07-13 11:54:35,546 INFO  [main] o.apache.spark.util.Utils: Successfully started service 'sparkDriver' on port 7078.
2022-07-13 11:54:35,578 INFO  [main] org.apache.spark.SparkEnv: Registering MapOutputTracker
2022-07-13 11:54:35,661 INFO  [main] org.apache.spark.SparkEnv: Registering BlockManagerMaster
2022-07-13 11:54:35,740 INFO  [main] o.a.s.s.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-07-13 11:54:35,740 INFO  [main] o.a.s.s.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-07-13 11:54:35,744 INFO  [main] org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2022-07-13 11:54:35,760 INFO  [main] o.a.s.s.DiskBlockManager: Created local directory at /var/data/spark-5cee8b94-f0ce-4732-9d9e-05ef5c0d0e0d/blockmgr-da517657-af42-453a-8aa0-01a526841c32
2022-07-13 11:54:35,822 INFO  [main] o.a.s.s.memory.MemoryStore: MemoryStore started with capacity 413.9 MiB
2022-07-13 11:54:35,849 INFO  [main] org.apache.spark.SparkEnv: Registering OutputCommitCoordinator
2022-07-13 11:54:36,047 INFO  [main] o.s.jetty.util.log: Logging initialized @8632ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-07-13 11:54:36,169 INFO  [main] o.s.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 1.8.0_262-b19
2022-07-13 11:54:36,241 INFO  [main] o.s.jetty.server.Server: Started @8827ms
2022-07-13 11:54:36,324 INFO  [main] o.s.j.s.AbstractConnector: Started ServerConnector@59e7564b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-07-13 11:54:36,325 INFO  [main] o.apache.spark.util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-07-13 11:54:36,362 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@6cdbe5ec{/jobs,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,365 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@22048bd6{/jobs/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,365 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@2e2f20b8{/jobs/job,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,366 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@60b1ff3b{/jobs/job/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,367 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@43c39321{/stages,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,368 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@3d0d120b{/stages/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,368 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@34d9df9f{/stages/stage,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,369 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@1192c925{/stages/stage/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,370 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@24691c5{/stages/pool,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,371 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@6537ac{/stages/pool/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,371 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@ddffa6c{/storage,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,372 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@6bb4cc0e{/storage/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,372 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@2e3f324e{/storage/rdd,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,373 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@b56ec6c{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,374 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@dc59ec2{/environment,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,374 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@bd93bc3{/environment/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,375 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@b01cb8d{/executors,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,429 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@7a814310{/executors/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,430 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@4e67cfe1{/executors/threadDump,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,433 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@25567581{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,445 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@67763ebe{/static,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,446 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@4df7d9ee{/,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,447 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@3a4e524{/api,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,448 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@7f4e5a39{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,449 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@30159886{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-07-13 11:54:36,451 INFO  [main] o.apache.spark.ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://spark-deb87d81f769087a-driver-svc.public.svc:4040
2022-07-13 11:54:36,468 INFO  [main] o.a.spark.SparkContext: Added JAR local:///opt/spark/jars/flare.jar at file:/opt/spark/jars/flare.jar with timestamp 1657713274628
2022-07-13 11:54:36,468 INFO  [main] o.a.spark.SparkContext: The JAR local:///opt/spark/jars/flare.jar at file:/opt/spark/jars/flare.jar has been added already. Overwriting of added jar is not supported in the current version.
2022-07-13 11:54:36,653 INFO  [main] o.a.s.d.k.SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
2022-07-13 11:54:37,836 INFO  [kubernetes-executor-snapshots-subscribers-0] o.a.s.s.c.k.ExecutorPodsAllocator: Going to request 1 executors from Kubernetes for ResourceProfile Id: 0, target: 1, known: 0, sharedSlotFromPendingPods: 2147483647.
2022-07-13 11:54:38,045 INFO  [kubernetes-executor-snapshots-subscribers-0] o.a.s.d.k.f.BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
2022-07-13 11:54:38,146 INFO  [main] o.apache.spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7079.
2022-07-13 11:54:38,147 INFO  [main] o.a.s.n.n.NettyBlockTransferService: Server created on spark-deb87d81f769087a-driver-svc.public.svc:7079
2022-07-13 11:54:38,149 INFO  [main] o.a.s.storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-07-13 11:54:38,158 INFO  [main] o.a.s.s.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, spark-deb87d81f769087a-driver-svc.public.svc, 7079, None)
2022-07-13 11:54:38,162 INFO  [dispatcher-BlockManagerMaster] o.a.s.s.BlockManagerMasterEndpoint: Registering block manager spark-deb87d81f769087a-driver-svc.public.svc:7079 with 413.9 MiB RAM, BlockManagerId(driver, spark-deb87d81f769087a-driver-svc.public.svc, 7079, None)
2022-07-13 11:54:38,225 INFO  [main] o.a.s.s.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, spark-deb87d81f769087a-driver-svc.public.svc, 7079, None)
2022-07-13 11:54:38,230 INFO  [main] o.a.s.storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, spark-deb87d81f769087a-driver-svc.public.svc, 7079, None)
2022-07-13 11:54:38,381 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@4070ace9{/metrics/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:43,056 INFO  [dispatcher-CoarseGrainedScheduler] o.a.s.s.c.k.KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.212.1.177:41530) with ID 1,  ResourceProfileId 0
2022-07-13 11:54:43,146 INFO  [main] o.a.s.s.c.k.KubernetesClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2022-07-13 11:54:43,337 INFO  [dispatcher-BlockManagerMaster] o.a.s.s.BlockManagerMasterEndpoint: Registering block manager 10.212.1.177:40577 with 413.9 MiB RAM, BlockManagerId(1, 10.212.1.177, 40577, None)
2022-07-13 11:54:43,787 INFO  [main] o.a.s.s.i.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2022-07-13 11:54:43,850 INFO  [main] o.a.s.s.i.SharedState: Warehouse path is 'file:/opt/spark/work-dir/spark-warehouse'.
2022-07-13 11:54:43,867 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@1686ed85{/SQL,null,AVAILABLE,@Spark}
2022-07-13 11:54:43,868 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@4fc3529{/SQL/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:43,869 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@3221588e{/SQL/execution,null,AVAILABLE,@Spark}
2022-07-13 11:54:43,869 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@32c0fecc{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:43,871 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@1f5d7fd5{/static/sql,null,AVAILABLE,@Spark}
2022-07-13 11:54:44,954 INFO  [main] o.a.s.s.e.s.s.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
2022-07-13 11:54:44,972 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@57920d6c{/StreamingQuery,null,AVAILABLE,@Spark}
2022-07-13 11:54:44,973 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@62cf86d6{/StreamingQuery/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:44,973 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@14d18029{/StreamingQuery/statistics,null,AVAILABLE,@Spark}
2022-07-13 11:54:44,974 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@75d7297d{/StreamingQuery/statistics/json,null,AVAILABLE,@Spark}
2022-07-13 11:54:44,975 INFO  [main] o.s.j.s.h.ContextHandler: Started o.s.j.s.ServletContextHandler@7438c3d5{/static/sql,null,AVAILABLE,@Spark}
2022-07-13 11:54:48,485 INFO  [main] o.e.hadoop.util.Version: Elasticsearch Hadoop v8.0.0 [647734dcda]
2022-07-13 11:54:50,036 INFO  [main] o.a.i.hadoop.HadoopTables: Table location loaded: abfss://lake001@dlake0mjslb0dsck0stg.dfs.core.windows.net/icebase/merchandise_retail/retail_customer
22/07/13 11:55:35 ERROR IosaPublisherService: could not publish audits to iosa receiver
io.dataos.metis.commons.iosa.IosaException: HttpClientException{body='null', statusCode=null, contentType='null', error='java.net.SocketTimeoutException: Read timed out'}
at io.dataos.metis.commons.iosa.IosaClient.post(IosaClient.java:92)
at io.dataos.flare.services.IosaPublisherService.$anonfun$publish$1(IosaPublisherService.scala:26)
at io.dataos.flare.services.IosaPublisherService.$anonfun$publish$1$adapted(IosaPublisherService.scala:25)
at io.github.resilience4j.retry.Retry.lambda$decorateFunction$7(Retry.java:355)
at io.dataos.flare.services.IosaPublisherService.publish(IosaPublisherService.scala:29)
at io.dataos.flare.auditor.GovernanceAuditor$.$anonfun$audit$1(GovernanceAuditor.scala:50)
at io.dataos.flare.auditor.GovernanceAuditor$.$anonfun$audit$1$adapted(GovernanceAuditor.scala:50)
at io.github.resilience4j.retry.Retry.lambda$decorateFunction$7(Retry.java:355)
at io.dataos.flare.auditor.GovernanceAuditor$.audit(GovernanceAuditor.scala:52)
at io.dataos.flare.utils.DataGovernor$.govern(DataGovernor.scala:57)
at io.dataos.flare.utils.DataGovernor$.govern(DataGovernor.scala:31)
at io.dataos.flare.Job.applyGovernance$1(Job.scala:130)
at io.dataos.flare.Job.$anonfun$registerDataframes$1(Job.scala:157)
at io.dataos.flare.Job.$anonfun$registerDataframes$1$adapted(Job.scala:110)
at scala.collection.immutable.List.foreach(List.scala:431)
at io.dataos.flare.Job.registerDataframes(Job.scala:110)
at io.dataos.flare.Job.<init>(Job.scala:71)
at io.dataos.flare.contexts.ProcessingContext.setup(ProcessingContext.scala:39)
at io.dataos.flare.Flare$.main(Flare.scala:61)
at io.dataos.flare.Flare.main(Flare.scala)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958)
at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:183)
at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:206)
at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046)
at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: HttpClientException{body='null', statusCode=null, contentType='null', error='java.net.SocketTimeoutException: Read timed out'}
at io.dataos.metis.commons.http.HttpClient.post(HttpClient.java:208)
at io.dataos.metis.commons.iosa.IosaClient.post(IosaClient.java:90)
... 31 more
Caused by: java.net.SocketTimeoutException: Read timed out
at java.net.SocketInputStream.socketRead0(Native Method)
at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
at java.net.SocketInputStream.read(SocketInputStream.java:171)
at java.net.SocketInputStream.read(SocketInputStream.java:141)
at org.apache.http.impl.io.SessionInputBufferImpl.streamRead(SessionInputBufferImpl.java:137)
at org.apache.http.impl.io.SessionInputBufferImpl.fillBuffer(SessionInputBufferImpl.java:153)
at org.apache.http.impl.io.SessionInputBufferImpl.readLine(SessionInputBufferImpl.java:280)
at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:138)
at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:56)
at org.apache.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:259)
at org.apache.http.impl.DefaultBHttpClientConnection.receiveResponseHeader(DefaultBHttpClientConnection.java:163)
at org.apache.http.impl.conn.CPoolProxy.receiveResponseHeader(CPoolProxy.java:157)
at org.apache.http.protocol.HttpRequestExecutor.doReceiveResponse(HttpRequestExecutor.java:273)
at org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:125)
at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:272)
at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
at io.dataos.metis.commons.http.HttpClient.post(HttpClient.java:201)
... 32 more
2022-07-13 11:55:36,225 WARN  [main] o.a.s.s.c.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
22/07/13 11:55:36 ERROR Flare$: =>Flare: Job finished with error build version: 5.7.12; workspace name: public; workflow name: retail-postgres-write; workflow run id: c9e73a1f-e0c8-4f27-9b26-fb82d12def08; run as user: rakeshvishvakarma; job name: retaildb-write-postgres; job run id: 23ac3e82-a24b-484b-a275-b47b5167e331;
io.dataos.flare.exceptions.FlareInvalidConfigException: username not found
at io.dataos.flare.utils.FlareUtils$.stringOrThrow(FlareUtils.scala:235)
at io.dataos.flare.output.writers.jdbc.JDBCOutputWriter.<init>(JDBCOutputWriter.scala:40)
at io.dataos.flare.output.WriterFactory$.get(WriterFactory.scala:69)
at io.dataos.flare.builders.TopologyBuilder$.$anonfun$addSinkInfoToDagOutputs$1(TopologyBuilder.scala:82)
at io.dataos.flare.builders.TopologyBuilder$.$anonfun$addSinkInfoToDagOutputs$1$adapted(TopologyBuilder.scala:81)
at scala.collection.immutable.List.foreach(List.scala:431)
at io.dataos.flare.builders.TopologyBuilder$.addSinkInfoToDagOutputs(TopologyBuilder.scala:81)
at io.dataos.flare.builders.TopologyBuilder$.$anonfun$buildDataframesUsingSteps$1(TopologyBuilder.scala:73)
at io.dataos.flare.builders.TopologyBuilder$.$anonfun$buildDataframesUsingSteps$1$adapted(TopologyBuilder.scala:72)
at scala.collection.immutable.List.foreach(List.scala:431)
at scala.collection.generic.TraversableForwarder.foreach(TraversableForwarder.scala:38)
at scala.collection.generic.TraversableForwarder.foreach$(TraversableForwarder.scala:38)
at scala.collection.mutable.ListBuffer.foreach(ListBuffer.scala:47)
at io.dataos.flare.builders.TopologyBuilder$.buildDataframesUsingSteps(TopologyBuilder.scala:72)
at io.dataos.flare.builders.TopologyBuilder$.extractOutputs(TopologyBuilder.scala:65)
at io.dataos.flare.builders.TopologyBuilder$.buildTopologyMeta(TopologyBuilder.scala:26)
at io.dataos.flare.contexts.ProcessingContext.buildAndRegisterTopology(ProcessingContext.scala:97)
at io.dataos.flare.contexts.ProcessingContext.setup(ProcessingContext.scala:44)
at io.dataos.flare.Flare$.main(Flare.scala:61)
at io.dataos.flare.Flare.main(Flare.scala)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958)
at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:183)
at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:206)
at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046)
at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2022-07-13 11:55:36,612 INFO  [main] o.q.i.StdSchedulerFactory: Using default implementation for ThreadExecutor
2022-07-13 11:55:36,617 INFO  [main] o.q.simpl.SimpleThreadPool: Job execution threads will use class loader of thread: main
2022-07-13 11:55:36,656 INFO  [main] o.q.c.SchedulerSignalerImpl: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2022-07-13 11:55:36,656 INFO  [main] o.q.core.QuartzScheduler: Quartz Scheduler v.2.3.2 created.
2022-07-13 11:55:36,658 INFO  [main] o.quartz.simpl.RAMJobStore: RAMJobStore initialized.
2022-07-13 11:55:36,659 INFO  [main] o.q.core.QuartzScheduler: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
NOT STARTED.
Currently in standby mode.
Number of jobs executed: 0
Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

2022-07-13 11:55:36,659 INFO  [main] o.q.i.StdSchedulerFactory: Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2022-07-13 11:55:36,659 INFO  [main] o.q.i.StdSchedulerFactory: Quartz scheduler version: 2.3.2
2022-07-13 11:55:36,660 INFO  [main] o.q.core.QuartzScheduler: Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED shutting down.
2022-07-13 11:55:36,660 INFO  [main] o.q.core.QuartzScheduler: Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED paused.
2022-07-13 11:55:36,661 INFO  [main] o.q.core.QuartzScheduler: Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED shutdown complete.
2022-07-13 11:55:36,780 INFO  [main] o.s.j.s.AbstractConnector: Stopped Spark@59e7564b{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-07-13 11:55:36,781 INFO  [main] o.apache.spark.ui.SparkUI: Stopped Spark web UI at http://spark-deb87d81f769087a-driver-svc.public.svc:4040
2022-07-13 11:55:36,786 INFO  [main] o.a.s.s.c.k.KubernetesClusterSchedulerBackend: Shutting down all executors
2022-07-13 11:55:36,787 INFO  [dispatcher-CoarseGrainedScheduler] o.a.s.s.c.k.KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking each executor to shut down
2022-07-13 11:55:36,796 WARN  [main] o.a.s.s.c.k.ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.
2022-07-13 11:55:36,970 INFO  [dispatcher-event-loop-0] o.a.s.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2022-07-13 11:55:36,982 INFO  [main] o.a.s.s.memory.MemoryStore: MemoryStore cleared
2022-07-13 11:55:36,982 INFO  [main] o.a.s.storage.BlockManager: BlockManager stopped
2022-07-13 11:55:37,030 INFO  [main] o.a.s.s.BlockManagerMaster: BlockManagerMaster stopped
2022-07-13 11:55:37,034 INFO  [dispatcher-event-loop-0] o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2022-07-13 11:55:37,043 INFO  [main] o.a.spark.SparkContext: Successfully stopped SparkContext
Exception in thread "main" io.dataos.flare.exceptions.FlareInvalidConfigException: username not found
at io.dataos.flare.utils.FlareUtils$.stringOrThrow(FlareUtils.scala:235)
at io.dataos.flare.output.writers.jdbc.JDBCOutputWriter.<init>(JDBCOutputWriter.scala:40)
at io.dataos.flare.output.WriterFactory$.get(WriterFactory.scala:69)
at io.dataos.flare.builders.TopologyBuilder$.$anonfun$addSinkInfoToDagOutputs$1(TopologyBuilder.scala:82)
at io.dataos.flare.builders.TopologyBuilder$.$anonfun$addSinkInfoToDagOutputs$1$adapted(TopologyBuilder.scala:81)
at scala.collection.immutable.List.foreach(List.scala:431)
at io.dataos.flare.builders.TopologyBuilder$.addSinkInfoToDagOutputs(TopologyBuilder.scala:81)
at io.dataos.flare.builders.TopologyBuilder$.$anonfun$buildDataframesUsingSteps$1(TopologyBuilder.scala:73)
at io.dataos.flare.builders.TopologyBuilder$.$anonfun$buildDataframesUsingSteps$1$adapted(TopologyBuilder.scala:72)
at scala.collection.immutable.List.foreach(List.scala:431)
at scala.collection.generic.TraversableForwarder.foreach(TraversableForwarder.scala:38)
at scala.collection.generic.TraversableForwarder.foreach$(TraversableForwarder.scala:38)
at scala.collection.mutable.ListBuffer.foreach(ListBuffer.scala:47)
at io.dataos.flare.builders.TopologyBuilder$.buildDataframesUsingSteps(TopologyBuilder.scala:72)
at io.dataos.flare.builders.TopologyBuilder$.extractOutputs(TopologyBuilder.scala:65)
at io.dataos.flare.builders.TopologyBuilder$.buildTopologyMeta(TopologyBuilder.scala:26)
at io.dataos.flare.contexts.ProcessingContext.buildAndRegisterTopology(ProcessingContext.scala:97)
at io.dataos.flare.contexts.ProcessingContext.setup(ProcessingContext.scala:44)
at io.dataos.flare.Flare$.main(Flare.scala:61)
at io.dataos.flare.Flare.main(Flare.scala)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958)
at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:183)
at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:206)
at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046)
at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055)
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
22/07/13 11:55:37 INFO Flare$: Gracefully stopping Spark Application
22/07/13 11:55:37 ERROR ProcessingContext: =>Flare: Job finished with error=username not found
Exception in thread "shutdownHook1" io.dataos.flare.exceptions.FlareException: username not found
at io.dataos.flare.contexts.ProcessingContext.error(ProcessingContext.scala:87)
at io.dataos.flare.Flare$.$anonfun$addShutdownHook$1(Flare.scala:84)
at scala.sys.ShutdownHookThread$$anon$1.run(ShutdownHookThread.scala:37)
2022-07-13 11:55:37,146 INFO  [shutdown-hook-0] o.a.s.u.ShutdownHookManager: Shutdown hook called
2022-07-13 11:55:37,147 INFO  [shutdown-hook-0] o.a.s.u.ShutdownHookManager: Deleting directory /tmp/spark-ed787a26-cc53-444e-af10-586c9d57c3ed
2022-07-13 11:55:37,153 INFO  [shutdown-hook-0] o.a.s.u.ShutdownHookManager: Deleting directory /var/data/spark-5cee8b94-f0ce-4732-9d9e-05ef5c0d0e0d/spark-a084079b-a283-4952-a02b-59572f92e9aa
